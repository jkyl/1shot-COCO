{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import json\n",
    "from textgen import *\n",
    "m = TextGen(\n",
    "    img_size=299, \n",
    "    code_dim=512, \n",
    "    rnn_type='LSTM', \n",
    "    cnn_type='InceptionV3',\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, val_record, ckpt, batch_size=32, capacity=8, n_threads=6, n_samples=10000, \n",
    "             inds_to_words_json='/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/inds_to_words.json'):\n",
    "    ''''''\n",
    "    with tf.variable_scope('BatchReader'):\n",
    "        print('creating batch reader')\n",
    "        coord =  tf.train.Coordinator()\n",
    "\n",
    "        # read and preprocess training records\n",
    "        x, y, c, id_ = model.read_tfrecord(\n",
    "            val_record, \n",
    "            batch_size=batch_size, \n",
    "            capacity=capacity, \n",
    "            n_threads=n_threads,\n",
    "            n_epochs=None, \n",
    "            shuffle=False)\n",
    "        x = model.preproc_img(x)\n",
    "        y, _ = model.preproc_caption(y, random=False)\n",
    "\n",
    "    with tf.variable_scope('Strings'):\n",
    "        print('getting strings')\n",
    "\n",
    "        y_hat = model.sample_recursively(x, batch_size=batch_size, \n",
    "                                         continuous=False)\n",
    "        table = model.create_table(inds_to_words_json)\n",
    "        y_strings = model.postproc_caption(y, table)\n",
    "        y_hat_strings = model.postproc_caption(y_hat, table)\n",
    "\n",
    "    with tf.Session(graph=model.graph) as sess:\n",
    "\n",
    "        print('initializing variables')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print('loading weights from '+ckpt)\n",
    "        model.load_weights(ckpt)\n",
    "        \n",
    "        print('starting threads')\n",
    "        tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        n = 0\n",
    "        results = []\n",
    "        try:\n",
    "            for _ in tqdm.trange(n_samples // batch_size):\n",
    "                if not coord.should_stop():\n",
    "                    s_hat, s, ids = sess.run([y_hat_strings, y_strings, id_], {backend.learning_phase(): False})\n",
    "                    s_hat, s = [[c.replace('SOS ', '').replace(' EOS', '') \\\n",
    "                                 for c in b] for b in s_hat, s]\n",
    "                    for i in range(batch_size):\n",
    "                        d = {\"image_id\": ids[i], \"caption\": s_hat[i]}\n",
    "                        results.append(d)\n",
    "                    n += batch_size\n",
    "                else:\n",
    "                    raise IOError, 'queues closed'\n",
    "            coord.request_stop()\n",
    "            time.sleep(0.2)\n",
    "            return results\n",
    "        # exit behaviour: request thread stop, then wait for \n",
    "        # them to recieve message before exiting session context\n",
    "        except:\n",
    "            coord.request_stop()\n",
    "            time.sleep(0.2)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating batch reader\n",
      "getting strings\n",
      "initializing variables\n",
      "loading weights from /home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [01:54<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "results = validate(m, \n",
    " '/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/val_1shot_NOVEL.tfrecord',\n",
    " '/home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5', \n",
    "n_samples=10000,\n",
    "batch_size=64)\n",
    "with open('novel.json', 'w') as fout:\n",
    "    json.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating batch reader\n",
      "getting strings\n",
      "initializing variables\n",
      "loading weights from /home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:03<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "results = validate(m, \n",
    " '/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/val_1shot_BASE.tfrecord',\n",
    " '/home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5', \n",
    "n_samples=10000,\n",
    "batch_size=64)\n",
    "with open('base.json', 'w') as fout:\n",
    "    json.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating batch reader\n",
      "getting strings\n",
      "initializing variables\n",
      "loading weights from /home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:17<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "results = validate(m, \n",
    " '/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/val_1shot.tfrecord',\n",
    " '/home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000550000.h5', \n",
    "n_samples=10000,\n",
    "batch_size=64)\n",
    "with open('all.json', 'w') as fout:\n",
    "    json.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
