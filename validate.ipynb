{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "%pylab inline\n",
    "from textgen import *\n",
    "\n",
    "m = TextGen(\n",
    "    img_size=299, \n",
    "    code_dim=512, \n",
    "    rnn_type='LSTM', \n",
    "    cnn_type='InceptionV3',\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def validate(model, val_record, ckpt, batch_size=64, capacity=8, n_threads=6, epoch_size=10000, \n",
    "             inds_to_words_json='/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/inds_to_words.json'):\n",
    "    ''''''\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.variable_scope('BatchReader'):\n",
    "            print('creating batch reader')\n",
    "\n",
    "            # coordinator for tf queues\n",
    "            coord =  tf.train.Coordinator()\n",
    "\n",
    "            # read and preprocess training records\n",
    "            x, y, cls = model.read_tfrecord(\n",
    "                val_record, \n",
    "                batch_size=batch_size, \n",
    "                capacity=capacity, \n",
    "                n_threads=n_threads,\n",
    "                n_epochs=None)\n",
    "            x = model.preproc_img(x)\n",
    "            y, _ = model.preproc_caption(y, random=False)\n",
    "\n",
    "        #with tf.variable_scope('StagingArea'):\n",
    "        #    print('creating staging area')\n",
    "\n",
    "        #    # create training queue on GPU\n",
    "        #    get, size, put = model.stage_data(\n",
    "        #        [x, y, cls], capacity=capacity)\n",
    "        #    x, y, cls = get\n",
    "\n",
    "        with tf.variable_scope('Metrics'):\n",
    "            print('getting metrics')\n",
    "\n",
    "            y_hat = model.sample_recursively(x, continuous=False)\n",
    "            table = model.create_table(inds_to_words_json)\n",
    "\n",
    "            y_inds, y_hat_inds = [tf.argmax(c, axis=-1) for c in (y, y_hat)]\n",
    "            y_strings, y_hat_strings = [tf.gather(table, c) for c in (y_inds, y_hat_inds)]\n",
    "\n",
    "            def bleu(data, pred):\n",
    "                bs = data.shape[0]\n",
    "                score = 0\n",
    "                for i in range(bs):\n",
    "                    y, y_hat = [[w for w in words if not w in ('SOS', 'EOS')] \\\n",
    "                                for words in data[i], pred[i]]\n",
    "                    score += sentence_bleu([y], y_hat, weights=[1], \n",
    "                                           smoothing_function=SmoothingFunction().method3)\n",
    "                score /= bs\n",
    "                return np.array(score, dtype='float32')\n",
    "\n",
    "            bleu_score = tf.py_func(bleu, [y_strings, y_hat_strings], tf.float32)\n",
    "\n",
    "        with tf.Session(graph=model.graph) as sess:\n",
    "            print('starting threads')\n",
    "\n",
    "            tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            #stop, threads = model.start_threads(\n",
    "            #    sess, put, n_stage_threads=n_threads)\n",
    "\n",
    "            print('initializing variables')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            print('loading weights from '+ckpt)\n",
    "            model.load_weights(ckpt)\n",
    "\n",
    "            #print('finalizing graph')\n",
    "            #model.graph.finalize()\n",
    "\n",
    "            score = 0.\n",
    "            n = 0.\n",
    "            try:\n",
    "                for _ in tqdm.trange(epoch_size):\n",
    "                    if not coord.should_stop():\n",
    "                        score += sess.run(bleu_score, {backend.learning_phase(): False})\n",
    "                        n += 1\n",
    "                        if n % 10 == 0:\n",
    "                            print(score / n)\n",
    "                    else:\n",
    "                        raise IOError, 'queues closed'\n",
    "\n",
    "            # exit behaviour: request thread stop, then wait for \n",
    "            # them to recieve message before exiting session context\n",
    "            except:\n",
    "                coord.request_stop()\n",
    "                time.sleep(0.2)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(m, \n",
    " '/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/val_crop_299_fullshot.tfrecord',\n",
    " '/home/paperspace/training/my_baseline/concat_reg_train/ckpt_update-0000050000.h5', \n",
    " batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
