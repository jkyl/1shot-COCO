{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from textgen import *\n",
    "\n",
    "m = TextGen(\n",
    "    img_size=299, \n",
    "    code_dim=512, \n",
    "    rnn_type='LSTM', \n",
    "    cnn_type='InceptionV3',\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, val_record, ckpt, batch_size=32, capacity=8, n_threads=6, epoch_size=10000, \n",
    "             captions_json='/home/paperspace/data/ms_coco/captions_val2014.json',\n",
    "             inds_to_words_json='/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/inds_to_words.json'):\n",
    "    ''''''\n",
    "    with tf.variable_scope('BatchReader'):\n",
    "        print('creating batch reader')\n",
    "        coord =  tf.train.Coordinator()\n",
    "\n",
    "        # read and preprocess training records\n",
    "        x, y, _ = model.read_tfrecord(\n",
    "            val_record, \n",
    "            batch_size=batch_size, \n",
    "            capacity=capacity, \n",
    "            n_threads=n_threads,\n",
    "            n_epochs=None)\n",
    "        x = model.preproc_img(x)\n",
    "        y, _ = model.preproc_caption(y, random=False)\n",
    "\n",
    "    with tf.variable_scope('Strings'):\n",
    "        print('getting strings')\n",
    "\n",
    "        y_hat = model.sample_recursively(x, continuous=False)\n",
    "        table = model.create_table(inds_to_words_json)\n",
    "        y_hat_strings = model.postproc_caption(y_hat, table)[0]\n",
    "\n",
    "    with tf.Session(graph=model.graph) as sess:\n",
    "        print('starting threads')\n",
    "        tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        print('initializing variables')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print('loading weights from '+ckpt)\n",
    "        model.load_weights(ckpt)\n",
    "        \n",
    "        print('loading IDs from '+captions_json)\n",
    "        ids = sorted([e['id'] for e in \\\n",
    "                json.loads(open(captions_json)\\\n",
    "                   .read())['images']])\n",
    "\n",
    "        n = 0\n",
    "        results = []\n",
    "        try:\n",
    "            for _ in tqdm.trange(epoch_size):\n",
    "                if not coord.should_stop():\n",
    "                    s = sess.run(y_hat_strings, {backend.learning_phase(): False})\n",
    "                    id_ = ids[n]\n",
    "                    for i, c in enumerate(s):\n",
    "                        d = {\"image_id\": id_[i], \"caption\": c}\n",
    "                    results.append(d)\n",
    "                    n += 1\n",
    "                else:\n",
    "                    raise IOError, 'queues closed'\n",
    "            return results\n",
    "        # exit behaviour: request thread stop, then wait for \n",
    "        # them to recieve message before exiting session context\n",
    "        except:\n",
    "            coord.request_stop()\n",
    "            time.sleep(0.2)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = validate(m, \n",
    " '/home/paperspace/data/ms_coco/SOS_preproc_vocab-9413_threshold-5_length-20/val_1shot.tfrecord',\n",
    " '/home/paperspace/training/1shot/lr4e-4_decay100k_bs16_reg1e-4_clip50_baseclasses/ckpt_update-0000890000.h5', \n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([e['id'] for e in \\\n",
    "        json.loads(open('/home/paperspace/data/ms_coco/captions_val2014.json')\\\n",
    "                   .read())['images']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
